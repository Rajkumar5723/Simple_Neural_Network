{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24959 images belonging to 2 classes.\n",
      "Found 4690 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RAJKUMAR\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RAJKUMAR\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m637/999\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 65ms/step - accuracy: 0.5715 - loss: 0.6722"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RAJKUMAR\\anaconda3\\Lib\\site-packages\\PIL\\TiffImagePlugin.py:870: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 75ms/step - accuracy: 0.5986 - loss: 0.6522 - val_accuracy: 0.7710 - val_loss: 0.4823\n",
      "Epoch 2/25\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 68ms/step - accuracy: 0.7513 - loss: 0.5069 - val_accuracy: 0.8002 - val_loss: 0.4345\n",
      "Epoch 3/25\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 69ms/step - accuracy: 0.7819 - loss: 0.4599 - val_accuracy: 0.8077 - val_loss: 0.4116\n",
      "Epoch 4/25\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 71ms/step - accuracy: 0.7999 - loss: 0.4307 - val_accuracy: 0.8328 - val_loss: 0.3631\n",
      "Epoch 5/25\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 68ms/step - accuracy: 0.8169 - loss: 0.4029 - val_accuracy: 0.8239 - val_loss: 0.3917\n",
      "Epoch 6/25\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 68ms/step - accuracy: 0.8238 - loss: 0.3863 - val_accuracy: 0.8518 - val_loss: 0.3337\n",
      "Epoch 7/25\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 68ms/step - accuracy: 0.8386 - loss: 0.3591 - val_accuracy: 0.8599 - val_loss: 0.3055\n",
      "Epoch 8/25\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 71ms/step - accuracy: 0.8522 - loss: 0.3360 - val_accuracy: 0.8429 - val_loss: 0.3347\n",
      "Epoch 9/25\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 68ms/step - accuracy: 0.8666 - loss: 0.3047 - val_accuracy: 0.8789 - val_loss: 0.2767\n",
      "Epoch 10/25\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 69ms/step - accuracy: 0.8776 - loss: 0.2828 - val_accuracy: 0.8940 - val_loss: 0.2484\n",
      "Epoch 11/25\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 69ms/step - accuracy: 0.8887 - loss: 0.2629 - val_accuracy: 0.9041 - val_loss: 0.2270\n",
      "Epoch 12/25\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 68ms/step - accuracy: 0.8974 - loss: 0.2450 - val_accuracy: 0.9262 - val_loss: 0.1808\n",
      "Epoch 13/25\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 103ms/step - accuracy: 0.9092 - loss: 0.2239 - val_accuracy: 0.9183 - val_loss: 0.1989\n",
      "Epoch 14/25\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 166ms/step - accuracy: 0.9162 - loss: 0.2048 - val_accuracy: 0.9437 - val_loss: 0.1413\n",
      "Epoch 15/25\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 68ms/step - accuracy: 0.9206 - loss: 0.1946 - val_accuracy: 0.9599 - val_loss: 0.1201\n",
      "Epoch 16/25\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 66ms/step - accuracy: 0.9308 - loss: 0.1776 - val_accuracy: 0.9618 - val_loss: 0.1014\n",
      "Epoch 17/25\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 66ms/step - accuracy: 0.9352 - loss: 0.1689 - val_accuracy: 0.9687 - val_loss: 0.0911\n",
      "Epoch 18/25\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 66ms/step - accuracy: 0.9410 - loss: 0.1506 - val_accuracy: 0.9618 - val_loss: 0.1065\n",
      "Epoch 19/25\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 66ms/step - accuracy: 0.9432 - loss: 0.1430 - val_accuracy: 0.9578 - val_loss: 0.1037\n",
      "Epoch 20/25\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 66ms/step - accuracy: 0.9432 - loss: 0.1430 - val_accuracy: 0.9802 - val_loss: 0.0656\n",
      "Epoch 21/25\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 66ms/step - accuracy: 0.9498 - loss: 0.1291 - val_accuracy: 0.9733 - val_loss: 0.0729\n",
      "Epoch 22/25\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 66ms/step - accuracy: 0.9568 - loss: 0.1179 - val_accuracy: 0.9520 - val_loss: 0.1178\n",
      "Epoch 23/25\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 66ms/step - accuracy: 0.9575 - loss: 0.1157 - val_accuracy: 0.9744 - val_loss: 0.0699\n",
      "Epoch 24/25\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 68ms/step - accuracy: 0.9608 - loss: 0.1076 - val_accuracy: 0.9554 - val_loss: 0.1123\n",
      "Epoch 25/25\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 94ms/step - accuracy: 0.9591 - loss: 0.1065 - val_accuracy: 0.9785 - val_loss: 0.0577\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "Prediction: cat\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2)\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set', target_size=(64,64), batch_size=25, class_mode='binary')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set', target_size=(64,64), batch_size=25, class_mode='binary')\n",
    "\n",
    "cnn = tf.keras.models.Sequential()\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "cnn.fit(x=training_set, validation_data=test_set, epochs=25)\n",
    "\n",
    "test_image = tf.keras.utils.load_img(\"dataset\\single_predicition\\download.jpeg\", target_size=(64,64))\n",
    "test_image = tf.keras.utils.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "result = cnn.predict(test_image)\n",
    "\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "\n",
    "print(\"Prediction:\", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Prediction: cat\n"
     ]
    }
   ],
   "source": [
    "test_image = tf.keras.utils.load_img(\"dataset\\single_predicition\\download (1).jpeg\", target_size=(64,64))\n",
    "test_image = tf.keras.utils.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "result = cnn.predict(test_image)\n",
    "\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "\n",
    "print(\"Prediction:\", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
